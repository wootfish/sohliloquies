---
layout: post
title: What Happened to Cyberspace?
author: Eli Sohl
---


> Governments of the Industrial World, you weary giants of flesh and steel, I come from Cyberspace, the new home of Mind. On behalf of the future, I ask you of the past to leave us alone. You are not welcome among us. You have no sovereignty where we gather.

\- [_A Declaration of the Independence of Cyberspace_](https://www.eff.org/cyberspace-independence)

> Cyberspace is the "place" where a telephone conversation appears to occur. Not inside your actual phone, the plastic device on your desk. Not inside the other person's phone, in some other city. The place between the phones. The indefinite place out there, where the two of you, two human beings, actually meet and communicate.
> Although it is not exactly "real," "cyberspace" is a genuine place. Things happen there that have very genuine consequences. This "place" is not "real," but it is serious, it is earnest. Tens of thousands of people have dedicated their lives to it, to the public service of public communication by wire and electronics.

\- [_The Hacker Crackdown_](http://www.mit.edu/hacker/hacker.html)

> Cyberspace. A consensual hallucination experienced daily by billions of legitimate operators, in every nation ... A graphical representation of data abstracted from the banks of every computer in the human system. Unthinkable complexity. Lines of light ranged in the non-space of the mind, clusters and constellations of data. Like city lights, receding.

\- [_Neuromancer_](https://archive.org/stream/NeuromancerWilliamGibson/Neuromancer%20-%20William%20Gibson_djvu.txt)

At first, no one really knew what the internet was for. We knew what it _was_, and people were coming up with all sorts of uses for it -- bulletin boards, instant messaging, mailing lists -- but there was this general sense that the internet's potential went far beyond any of that. Bigger things were coming; it's just that no one quite knew what they would look like. To capture this sense of excited uncertainty, sci-fi authors of the '80s and '90s leaned heavily on the idea of _cyberspace_.[^1]

[^1]: Style note: Throughout this post, _"cyberspace"_ refers to the word _cyberspace_ if italicized, and the concept of cyberspace otherwise.

As a metaphor, _cyberspace_ was popular because it captured the sheer breadth of possibilities that exist with networked technology. By suggesting an analogue to physical space, which has been the venue for the entire range of analog human experience, _cyberspace_ seemed to suggest a limitless new domain: new experiences, new possibilities, new potentialities. It's an exciting thought. Fast-forward to 2019, and we've fallen a bit short of expectations. Many people's experience of the modern internet consists of four web sites, each of which is largely comprised of screenshots from the other three.

OK, maybe that's a bit much. But grant me that bit of hyperbole and in return I'll let you in on a secret: cyberspace hasn't gone away. We're still in it, we've just been spending all our time in the wrong places.

Architecturally, the modern web is built around a client-server model: data requesters (like you, loading up Twitter) and data providers (like Twitter, sending you fresh tweets). This data lives on servers; the servers live in some large air-conditioned room with armed guards; these servers dole out data to clients like yourself at-will. What sort of (cyber-)space does this create? Who, if anyone, owns it? Does the service's owner have power over you? Certainly they do, and certainly they own the space -- though most major companies go to great pains to obfuscate this fact.

Early on in _The Hacker Crackdown_ , while chronicling the development of the phone network, Bruce Sterling recounts how, in the late 1800s, telephone technology was first normalized:

> After a year or so, Alexander Graham Bell and his capitalist backers concluded that eerie music piped from nineteenth-century cyberspace was not the real selling point of his invention. Instead, the telephone was about speech -- individual, personal speech, the human voice, human conversation and human interaction. The telephone was not to be managed from any centralized broadcast center. It was to be a personal, intimate technology.
>
> When you picked up a telephone, you were not absorbing the cold output of a machine -- you were speaking to another human being. Once people realized this, their instinctive dread of the telephone as an eerie, unnatural device, swiftly vanished. A "telephone call" was not a "call" from a "telephone" itself, but a call from another human being, someone you would generally know and recognize. The real point was not what the machine could do for you (or to you), but what you yourself, a person and citizen, could do through the machine.

Modern social media sites have learned this lesson well: while the _individual interactions_ taking place over the web are always between you and various servers, the _perceived interactions_ are between you and your friends (or enemies, if you're that particular sad sort of person)[^2]. It's easy to forget that everything you do is being proxied through these third-party servers. This humanization of the technology obscures an important fact: social media services' interposition into your interactions with your friends means that these interactions are effectively taking place _on private property_ belonging to not to you or your friends but to the service you are using.

[^2]: For instance, suppose you post a tweet, and a friend of yours retweets it. Technically, the interactions here are: you contact Twitter's servers and ask them to store a new tweet from your account on your behalf; Twitter accepts your request; your friend contacts Twitter's servers, asking for fresh tweets; Twitter accepts your friend's request and shows them your tweet; your friend contacts Twitter's servers again, asking to retweet your tweet; Twitter accepts this request as well; soon after, your Twitter app contacts Twitter's servers of its own volition on your behalf, asking for new notifications, and Twitter responds with the news that you have been retweeted. Note how you and your friend do not at any point interact directly over the network, even though the _perceived_ interaction is between you and them: you post a tweet; your friend retweets it; you see that your friend has retweeted it.

Now, there are some big advantages to building web sites with this centralized, business-run, private-property model. We've spent a long time doing things this way, and we've gotten pretty good at it, and there are lots of centralized web sites that we wouldn't know how to build any other way.

That said, there are also significant drawbacks to this model. Servers aren't cheap. Most web sites have needed to make money to stay online, which turns out to be pretty difficult. Hence, the advent of online advertising, which has since been described (by people who would know) as [the original sin](https://www.theatlantic.com/technology/archive/2014/08/advertising-is-the-internets-original-sin/376041/) of the internet.

Decades down the road, we've discovered that the digital ad ecosystem is [just as bad](http://nymag.com/intelligencer/2018/12/how-much-of-the-internet-is-fake.html) as any other funding model we tried -- it just has a less obvious failure state. However, the lifeblood of this ecosystem -- tracking data, the more personal the better -- has turned out to be tremendously valuable in a whole lot of ways (for more on this, there are many books I'd recommend but none as much as _Data and Goliath_, which you can find my notes on [here](https://wootfish.github.io/sohliloquies/2017/09/12/book-notes.html)). Apparently there's a lot of money to be made on invading people's privacy.

And so, even as ad-based revenue models are looking more and more like a dead-end, the tactics used to deliver targeted advertisements have turned out to be a goldmine of incredibly personal information. This information is readily bought and sold, and (needless to say) the people buying information about you rarely have your best interests in mind. It is used to [deny loans](TODO), to [raise interest premiums](TODO), to [deliver hate speech](TODO), to [single out the most vulnerable in society](TODO) for manipulation, to (when handled sloppily, as is almost always the case) out [pseudonymous performers](TODO), [members of anonymous recovery groups](TODO), ...TODO..., and more.

All this is horrifying and disgusting. It is a fundamental breach of trust, committed casually and constantly. The thing is, the market doesn't care: there's a profit incentive for companies to collect and monetize this data, so collect and monetize they do. And as long as we're spending all our time in their private corners of cyberspace, there's nothing we can do about it. It's like we're carrying out our entire social lives in a mall's highly surveilled food court, with the mall transcribing all our conversations and [selling them to the highest bidder](https://www.theguardian.com/technology/2018/dec/19/facebook-shared-user-data-private-messages-netflix-spotify-amazon-microsoft-sony).

One response to this unintended consequence of centralized systems has been to build new, _federated_ systems for social media. The idea is this: instead of having a service provided by a big, monolithic server (or set of servers) owned and operated by one company, federated systems are comprised of a number of smaller, volunteer-run servers, which collaborate to provide a similar experience to centralized web sites. Distributing responsibility in this way also distributes ownership (somewhat!), limiting the amount of data that can be collected on users. It is further assumed that altruistic volunteers are less likely to indulge in invasive tracking, as well as perhaps less technically capable of implementing it.

The move from centralized to federated sites brings with it some welcome changes. One can have a (somewhat) greater degree of confidence that the platform is respecting one's privacy. This is something like swearing off the food court and hanging out at someone's house instead: It's chill, as long as they're chill. But you're still on _someone's_ private property, so you're still placing trust in someone, [and things can still go very wrong](https://www.cbsnews.com/news/airbnb-guests-find-hidden-cameras/). Perhaps the most popular federated social media site in 2018 is Mastodon, which [is actually doing pretty OK, as these things go](https://motherboard.vice.com/en_us/article/783akg/mastodon-is-like-twitter-without-nazis-so-why-are-we-not-using-it), but which still has a long way to go before it can claim serious adoption (and they might want to find a better word than 'toot' for their version of tweets -- but what do I know).

With all federated services, you make a number of compromises. You lose the certainty of a monolithic corporation data-mining everything you do or say through them, but you pick up the risk of random individual strangers trying to do the same.

You also place your trust in these strangers' abilities as sysadmins, which is a lot of responsibility to leave on an unpaid stranger's shoulders, especially long-term. You lose the skilled, well-paid security teams of large companies -- teams who work hard every day to protect your data by making sure it gets leaked only to those who are paying for it and no one else. In their place you have some poor specific individual sucker and just really hope they're doing their best even though they're defintely not getting paid enough for this shit.

Overall, federation represents an improvement on centralization, but it carries over a number of centralization's problems, a few of which are made much worse. The story of federated systems is in many ways the story of centralized systems, but writ small and heavily repeated.

If we want to get away from this set of issues, perhaps it makes sense to get away from centralization entirely. At the polar opposite from centralized systems are _distributed_ systems, peer-to-peer networks with protocols that provide a service through the power of mutual aid.

Perhaps the most famous example of a distributed, peer-to-peer system is BitTorrent, which was recently reported to constitute [22% of all internet traffic globally](https://torrentfreak.com/bittorrent-traffic-is-not-dead-its-making-a-comeback-180926/) (for scale, Netflix claims to be responsible for 15%).

The premise of BitTorrent is this: you break large files up into small chunks, and you download a bunch of these chunks at a time in parallel from a bunch of different people. Once you've downloaded part of a file, you can start sending those parts to other downloaders, and perhaps they will reciprocate (or perhaps they won't -- and that's ok, because there are enough generous uploaders that a few unhelpful peers don't spoil the thing for everyone). In the end, as long as the honest peers in the network collectively possesses all parts of the file, everyone will be able to download the whole thing -- and the whole process is usually a lot faster and more fault-tolerant than it would be if you were downloading from a single source.

We might well ask: what sort of cyberspace are you taking part in when you join a BitTorrent peer swarm? Does anyone own this space? The network itself is totally ad-hoc (although your introduction point to it might not be). You have no client-server relationships, only peer-to-peer. There are no mediators; no social-media giants are interposing themselves into your interactions. This is not to say you're completely secure -- you still have to trust your peers, somewhat, but the range of misbehavior that peers are capable of is much, much more limited than what a corporation (or even a federated system's node's maintainer) can and will do.

Of course, BitTorrent is a pretty limited application. It does one thing, and does it well -- but it only does one thing. What else are distributed, peer-to-peer systems capable of? In spite of decades of research, that is still something of an open question in 2018, but it's one that I'd very much like to see more exploration of. Much of the internet's untapped potential lies in peer-to-peer systems.

I mentioned earlier that one sticking point with BitTorrent is getting an introduction to a peer swarm. Once you've met some peers, you're set, but getting to that point can be tricky. How is it done today?

The "traditional" way to get started is via a _peer tracker_, a centralized service that peers can register themselves with and which in turn serves up a list of registered peers on demand. Not only is this a central point of surveillance, it is a central point of failure (as the Pirate Bay folks and many before them learned the hard way).

A step beyond running a peer tracker is to offer _mirrors_, essentially a federation of the tracker service. In this methodology, a bunch of folks grab the same content index and start serving up their own trackers from it, essentially forcing copyright regulators and their ilk to play whack-a-mole to try to take everyone down.

A step further is to use _magnet links_. The way these work, frankly, is one step removed from magic. A magnet link is a small string, short enough to easily copy-paste or even transcribe by hand (if you're a good typist). This string defines an _address_ where one can look to get details of a torrent, and a list of peers for that torrent. But where do you look? Not on a web site, but rather in something called a _distributed hash table_ or DHT.

A DHT is essentially a very simple database that a bunch of peers collectively maintain, a little bit like an employee-run company that anyone can join. It works off a peer-to-peer protocol, much like BitTorrent does, but this protocol offers something different. It lets you store small chunks of data (like the contact info other peers need to connect to you) at addresses (like the one you get from your magnet link), and it lets you query any address to see all the data everyone has stored there. Anyone can connect to it, anyone can store data on it, and anyone can get data from it. Some people maintain a very long-lived presence in the network, serving as reliable points for reconnection. This is where your computer goes to resolve magnet links, and honestly, the whole thing almost seems too good to be true.

To return to an unanswered question: how do we characterize such a (cyber-)space as this? I'm inclined to look at it as _public cyberspace_. It's like a public park or library -- something which exists because a small number of people care enough to look after it, and which therefore is available for a huge number of people to enjoy, free of cost. No one owns it -- we just coexist within it. This somehow seems to leave more space for the potential-filled visions of early cyberspace enthusiasts.

There's a reason it seems almost too good to be true: it almost is. Malicious interference in peer-to-peer systems turns out to often be very easy. BitTorrent protects against this with error-checking codes -- as long as you have a torrent file describing the file you're trying to download, you'll be able to validate every chunk of it and keep your peers honest -- but with a construct like a DHT there is no such single source of truth, no authoritative method of validation. It turns out that most existing networks are very easy to mess with, in part because no one has a full view of the system.

The _Sybil attack_ consists of deploying a huge number of peers on the network -- peers which you control, but which look like distinct entities to anyone else. This gives you a lot of leverage, and while each DHT protocol fails differently, they all do fail sooner or later. It has been proven that [perfect defense against Sybil attacks is impossible](TODO) (then again, if we're keeping score, it could be argued that perfect defense against standard threats for a large corporation is impossible too). The DHT that most magnet link resolutions go through, _Mainline DHT_, makes no attempts at defending against Sybil attacks, and experiences [many of them each day](TODO). These attacks have the potential to completely and arbitrarily censor data from MLDHT.

While perfect defense against Sybil attacks does not appear to be possible, countermeasures do exist. The Theseus DHT project, which I have been working on nonstop since early 2016, exists to explore these. The approach taken is much more analytic than most previous work, and the results this project has achieved so far are very encouraging.

A construct like Theseus DHT, if successfully realized, could provide many useful services. It could support all sorts of ephemeral data sharing and storage, serving as a data layer for entirely new app architectures. It's a natural fit, too, for making introductions to peer swarms: the fact that Theseus DHT is resilient against Sybil attacks makes it preferable to MLDHT for this purpose, as does the fact that it uses strong encryption to help protect peers' privacy even under pervasive surveillance.

What this means is that a system like Theseus DHT would be not only a powerful construct in its own right but a potential bootstrapping point for the next generation of peer-to-peer apps -- a layer on which they can build, a substrate, a common good commonly used and maintained, with common benefit. We should be so lucky as for this to be the future.
